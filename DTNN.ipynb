{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import utils\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_atoms = 5\n",
    "max_atoms = 30\n",
    "num_atoms = 110\n",
    "basis = 3\n",
    "num_gauss = 5\n",
    "hidden = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zs, Ds, sizes = utils.create_dummy_batch(min_atoms, max_atoms, num_atoms, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 21, 11, 24, 21, 15,  6, 25,  7, 28, 25, 22, 20, 27,  5, 16, 13, 21,\n",
       "        29, 11])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionBlock(nn.Module):\n",
    "    def __init__(self, basis, hidden):\n",
    "        super().__init__()\n",
    "        self.cf = nn.Linear(basis, hidden)\n",
    "        self.fc = nn.Linear(hidden, basis, False)\n",
    "    \n",
    "    def forward(self, C, D_hat, sizes):\n",
    "        X = self.cf(C)\n",
    "        X = X.unsqueeze(-2) * D_hat\n",
    "        X = torch.tanh(self.fc(X))\n",
    "        \n",
    "        num_batch = C.shape[0] if len(C.shape) > 2 else 1\n",
    "        mask = utils.mask_2d(sizes, max_atoms)\n",
    "        return (mask.unsqueeze(-1) * X).sum(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDTNN(nn.Module):\n",
    "    def __init__(self, basis, num_atoms, num_gauss, hidden, T=3):\n",
    "        super().__init__()\n",
    "        self.basis = basis\n",
    "        self.T = T\n",
    "        \n",
    "        self.C_embed = nn.Embedding(num_atoms + 1, basis)\n",
    "        self.df = nn.Linear(num_gauss, hidden)\n",
    "        self.interaction = InteractionBlock(basis, hidden)\n",
    "        self.mlp = nn.Sequential(nn.Linear(basis, hidden),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(hidden, 1))\n",
    "    \n",
    "    def forward(self, Z, D, sizes):\n",
    "        C = self.C_embed(Z)\n",
    "        d_hat = self.df(D)\n",
    "        \n",
    "        for _ in range(self.T):\n",
    "            C = C + self.interaction(C, d_hat, sizes)\n",
    "            \n",
    "        E = self.mlp(C).squeeze()\n",
    "        mask = utils.mask_1d(sizes, max_atoms)\n",
    "        \n",
    "        return (mask * E).sum(-1)#.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MDTNN(basis, num_atoms, num_gauss, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[101,   7,  52,  55,   5,  52,  35,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 88,  18,  56,  62,  65,  29,  52,  46,  37,  23,  18,  56,  29, 107,\n",
       "          76,  49,  66,  12,  13,  25,  31,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 50,  81,  96,  20,  26, 104,  76,  41,  97,  74,  50,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 93,  21,  40,  52,  23,  90,  70,  83,  30,  66,  86,  27,  29,  21,\n",
       "          76,  90,  15,  72,  25, 103,  84,  94,  32,  36,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 78,  69,  96,  10,  64,  47,  77,  51,  65,  88,  11,  87,   2,  20,\n",
       "          21,  40,  54,  31,  94,  67,  58,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 83,   7, 109,  62,  61,  31, 105,  41,   7, 100,  69,  16,  77,  36,\n",
       "         101,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 74,  35,  95,  72,  48,  53,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 64,  14,  64,   8,  97,   3,  34,  80, 107,  87,  95,  40,  57,   3,\n",
       "          85,  26,  99,  76,  59, 101,  46,   9,  90,  65,  62,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 14,  76,  14,  83,  48, 109,  93,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [102,  77,   1,  48,  51,   4,  23, 102,  56,  74,  47,  39,  83,  13,\n",
       "          38,  44,  19, 102,  15, 105,  10,  84,  96,  53,  93,  28,  18,  91,\n",
       "           0,   0],\n",
       "        [ 35,  17,  77,  50,   6,   1,   5,  65,  51,  79,  34,  54,  66,  63,\n",
       "         107,  54,  74,  35,   7,  46,  40,  46,  54, 108,  90,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 97,  59,  81,  36,  72,  85,  54,  77,  12,  57,  29,   3,  58,  66,\n",
       "          43, 106,  56,  66,  15,  40,  38,  50,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 83,  74,  78,  79,  64,  36,   7,  77,  69,  95,  89,   8,  81,   4,\n",
       "          20,  59,  26,  30,  70,  71,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [108, 104,  99,  41, 106,  81,  15,  25,  86, 103,   8,  56,  28,  92,\n",
       "          80,  90,  45,  58,  44,  40,  83,  46,  63,  47,  54,  90,  13,   0,\n",
       "           0,   0],\n",
       "        [ 84,  53,  99,  35,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 38,  57,  14,  96,  51,   8,  90,  69,  73,  91, 109,  43,  22,  88,\n",
       "          13,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 53,  80,  51, 105,  47,  27,  20, 102,  23,  27,  55,  43,  77,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 34, 100,  64,  43,  44, 104,  14,  59,  55, 108,  58,  45,  82,  70,\n",
       "         102,   3,  17,  88,  70,  42,  12,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 97,   1,   8,  79,  40,  90,  73,  51,  93,  63,  44,  71,  55,   8,\n",
       "          70,  25,  40,  24,  93,  10,  82,  53,  74,  22,   7,  60,   8,  80,\n",
       "          81,   0],\n",
       "        [ 55,  22,  92, 106,  37,  49,  46,  46,  27,  85,  37,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.4549,  2.1654,  9.1737,  9.2142, 13.4600,  8.7968,  2.9231,  6.5949,\n",
       "         3.0562,  8.3927,  8.8697, -1.3868, 11.5769, 14.8065,  3.2132,  9.8461,\n",
       "         9.2581,  0.4544, 22.2138,  7.0638], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(Zs, utils.transform_D(Ds, num_gauss), sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTNNModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dtnn = MDTNN(basis, num_atoms, num_gauss, hidden)\n",
    "    \n",
    "    def forward(self, Z, D, sizes):\n",
    "        return self.dtnn(Z, D, sizes)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(data.QM8Dataset('E1-CC2', max_atoms, num_gauss), 15)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        Z, D, sizes, target = batch\n",
    "        predict = self.forward(Z, D, sizes)\n",
    "        loss = F.mse_loss(predict, target)\n",
    "        return {'loss': loss,\n",
    "                'log': {'train_loss': loss}}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/ptigwe/.pyenv/versions/miniconda-latest/envs/elix/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name | Type  | Params\n",
      "-------------------------------\n",
      "0 | dtnn | MDTNN | 442   \n",
      "/home/ptigwe/.pyenv/versions/miniconda-latest/envs/elix/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554f261fe6564beca2ea79b524998b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptigwe/.pyenv/versions/miniconda-latest/envs/elix/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DTNNModule()\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
