{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_(X, max_atoms, dim=1):\n",
    "    extra = max_atoms - X.shape[0]\n",
    "    return F.pad(X, (0, extra) * dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy(num_atoms, total_atoms):\n",
    "    Z = torch.LongTensor(num_atoms).random_(total_atoms)\n",
    "    D = torch.rand((num_atoms, num_atoms))\n",
    "    D.masked_fill_(torch.eye(num_atoms).bool(), 0)\n",
    "    return Z + 1, (D + D.T) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_batch(min_atoms, max_atoms, total_atoms, bs):\n",
    "    Zs, Ds, sizes = [], [], []\n",
    "    for num_atoms in torch.randint(min_atoms, max_atoms, (bs,)):\n",
    "        Z, D = create_dummy(num_atoms.item(), total_atoms)\n",
    "        Zs.append(pad_(Z, max_atoms))\n",
    "        Ds.append(pad_(D, max_atoms, 2))\n",
    "        sizes.append(num_atoms)\n",
    "    Zs = torch.stack(Zs)\n",
    "    Ds = torch.stack(Ds)\n",
    "    return Zs, Ds, torch.LongTensor(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_D(D, sz):\n",
    "    shape = list(D.shape) + [sz]\n",
    "    return D.unsqueeze(-1).expand(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_atoms = 5\n",
    "max_atoms = 10\n",
    "num_atoms = 100\n",
    "basis = 3\n",
    "num_gauss = 5\n",
    "hidden = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zs, Ds, sizes = create_dummy_batch(min_atoms, max_atoms, num_atoms, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 46,  27,  75,   7,  48,  48,   0,   0,   0,   0],\n",
       "        [  6,  64,  82,  16,  83,  23,   0,   0,   0,   0],\n",
       "        [ 35,   9,  61,  21,  48,   0,   0,   0,   0,   0],\n",
       "        [ 26,  84,  19,  85,  75,  97,  55,  50,  98,   0],\n",
       "        [ 45,  29,  19,  24,  61,  13,  95,  35,  12,   0],\n",
       "        [ 36,  17,  98,  61,  38,  79,  90,  58,  35,   0],\n",
       "        [ 74,  50,  97,   8,  64,   0,   0,   0,   0,   0],\n",
       "        [ 51,  82,  68,  98,  45,  42,  22,   0,   0,   0],\n",
       "        [ 65,  36,  27,  72,  76,  63,  43,  67,   0,   0],\n",
       "        [ 85,  62,  58,  30,  69,  17,  52,   0,   0,   0],\n",
       "        [ 42,  99,  65,  84,  54,  83,  23,  78,  11,   0],\n",
       "        [ 47,   8,  86,  68,  91,  33,  78,  26,   0,   0],\n",
       "        [ 86,  62,  96,  24,  62,  38,  50,   1,  68,   0],\n",
       "        [ 67,  56,  65,  21,  44,   5,  60,   0,   0,   0],\n",
       "        [ 71,  24,   3,  92,  57,  40, 100,  43,  14,   0],\n",
       "        [ 84,  83,  95,  41,  26,  10,  91,  18,   0,   0],\n",
       "        [ 14,   5,  84,  25,   7,  21,  61,  59,   0,   0],\n",
       "        [ 37,  73,  59,  76,  35,   0,   0,   0,   0,   0],\n",
       "        [ 88,  57,  38,   9,  11,  35,  74,   0,   0,   0],\n",
       "        [ 35,  54,  88,  39,  90,  59,  72,  12,   0,   0]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 9, 7, 8, 7, 6, 6, 7, 7, 5])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(sizes, full_size):\n",
    "    masks = []\n",
    "    \n",
    "    for size in sizes:\n",
    "        mask = torch.zeros((full_size, full_size))\n",
    "        mask[np.diag_indices(size)] = 1\n",
    "        mask[:size, :size] -= 1\n",
    "        mask.abs_()\n",
    "        masks.append(mask)\n",
    "    \n",
    "    return torch.stack(masks) if len(sizes) > 1 else mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_1d(sizes, full_size):\n",
    "    masks = []\n",
    "    \n",
    "    for size in sizes:\n",
    "        mask = torch.zeros((full_size,))\n",
    "        mask[:size] = 1\n",
    "        masks.append(mask)\n",
    "    \n",
    "    return torch.stack(masks) if len(sizes) > 1 else mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionBlock(nn.Module):\n",
    "    def __init__(self, basis, hidden):\n",
    "        super().__init__()\n",
    "        self.cf = nn.Linear(basis, hidden)\n",
    "        self.fc = nn.Linear(hidden, basis, False)\n",
    "    \n",
    "    def forward(self, C, D_hat, sizes):\n",
    "        X = self.cf(C)\n",
    "        X = X.unsqueeze(-2) * D_hat\n",
    "        X = torch.tanh(self.fc(X))\n",
    "        \n",
    "        num_batch = C.shape[0] if len(C.shape) > 2 else 1\n",
    "        mask = create_mask(sizes, max_atoms)\n",
    "        return (mask.unsqueeze(-1) * X).sum(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDTNN(nn.Module):\n",
    "    def __init__(self, basis, num_atoms, num_gauss, hidden, T=3):\n",
    "        super().__init__()\n",
    "        self.basis = basis\n",
    "        self.T = T\n",
    "        \n",
    "        self.C_embed = nn.Embedding(num_atoms + 1, basis)\n",
    "        self.df = nn.Linear(num_gauss, hidden)\n",
    "        self.interaction = InteractionBlock(basis, hidden)\n",
    "        self.mlp = nn.Sequential(nn.Linear(basis, hidden),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(hidden, 1))\n",
    "    \n",
    "    def forward(self, Z, D, sizes):\n",
    "        C = self.C_embed(Z)\n",
    "        d_hat = self.df(D)\n",
    "        \n",
    "        print(C.shape)\n",
    "        print(d_hat.shape)\n",
    "        for _ in range(self.T):\n",
    "            C += self.interaction(C, d_hat, sizes)\n",
    "            \n",
    "        E = self.mlp(C).squeeze()\n",
    "        mask = create_mask_1d(sizes, max_atoms)\n",
    "        \n",
    "        return (mask * E).sum(-1)#.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MDTNN(basis, num_atoms, num_gauss, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 46,  27,  75,   7,  48,  48,   0,   0,   0,   0],\n",
       "        [  6,  64,  82,  16,  83,  23,   0,   0,   0,   0],\n",
       "        [ 35,   9,  61,  21,  48,   0,   0,   0,   0,   0],\n",
       "        [ 26,  84,  19,  85,  75,  97,  55,  50,  98,   0],\n",
       "        [ 45,  29,  19,  24,  61,  13,  95,  35,  12,   0],\n",
       "        [ 36,  17,  98,  61,  38,  79,  90,  58,  35,   0],\n",
       "        [ 74,  50,  97,   8,  64,   0,   0,   0,   0,   0],\n",
       "        [ 51,  82,  68,  98,  45,  42,  22,   0,   0,   0],\n",
       "        [ 65,  36,  27,  72,  76,  63,  43,  67,   0,   0],\n",
       "        [ 85,  62,  58,  30,  69,  17,  52,   0,   0,   0],\n",
       "        [ 42,  99,  65,  84,  54,  83,  23,  78,  11,   0],\n",
       "        [ 47,   8,  86,  68,  91,  33,  78,  26,   0,   0],\n",
       "        [ 86,  62,  96,  24,  62,  38,  50,   1,  68,   0],\n",
       "        [ 67,  56,  65,  21,  44,   5,  60,   0,   0,   0],\n",
       "        [ 71,  24,   3,  92,  57,  40, 100,  43,  14,   0],\n",
       "        [ 84,  83,  95,  41,  26,  10,  91,  18,   0,   0],\n",
       "        [ 14,   5,  84,  25,   7,  21,  61,  59,   0,   0],\n",
       "        [ 37,  73,  59,  76,  35,   0,   0,   0,   0,   0],\n",
       "        [ 88,  57,  38,   9,  11,  35,  74,   0,   0,   0],\n",
       "        [ 35,  54,  88,  39,  90,  59,  72,  12,   0,   0]])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 10, 3])\n",
      "torch.Size([20, 10, 10, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.3407, 2.9144, 2.4607, 4.6193, 5.1044, 3.1283, 2.4735, 3.9668, 4.6154,\n",
       "        2.5609, 5.5254, 2.5080, 3.8188, 2.4784, 3.5806, 4.6213, 3.8068, 2.5653,\n",
       "        2.2554, 2.9945], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(Zs, transform_D(Ds, num_gauss), sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3930, 0.5242, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3930, 0.0000, 0.6171, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5242, 0.6171, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(D, (0, 5, 0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.3930, 0.5242, 0.0000])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(D[0], (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_atoms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-342-350eacf5723d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_atoms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'max_atoms' is not defined"
     ]
    }
   ],
   "source": [
    "create_mask(sizes, max_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
