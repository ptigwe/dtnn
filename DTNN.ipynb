{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import utils\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_atoms = 5\n",
    "max_atoms = 30\n",
    "num_atoms = 110\n",
    "mu_min = -1\n",
    "mu_max = 10\n",
    "delta_mu = 0.2\n",
    "basis = 30\n",
    "num_gauss = int((mu_max - mu_min) / delta_mu) + 1\n",
    "hidden = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zs, Ds, sizes = utils.create_dummy_batch(min_atoms, max_atoms, num_atoms, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionBlock(nn.Module):\n",
    "    def __init__(self, basis, hidden):\n",
    "        super().__init__()\n",
    "        self.cf = nn.Linear(basis, hidden)\n",
    "        self.fc = nn.Linear(hidden, basis, False)\n",
    "    \n",
    "    def forward(self, C, D_hat, sizes):\n",
    "        X = self.cf(C)\n",
    "        X = X.unsqueeze(-2) * D_hat\n",
    "        X = torch.tanh(self.fc(X))\n",
    "        \n",
    "        num_batch = C.shape[0] if len(C.shape) > 2 else 1\n",
    "        mask = utils.mask_2d(sizes, max_atoms)\n",
    "        mask = mask.to(X.device)\n",
    "        return (mask.unsqueeze(-1) * X).sum(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDTNN(nn.Module):\n",
    "    def __init__(self, basis, num_atoms, num_gauss, hidden, T=3):\n",
    "        super().__init__()\n",
    "        self.basis = basis\n",
    "        self.T = T\n",
    "        \n",
    "        self.C_embed = nn.Embedding(num_atoms + 1, basis)\n",
    "        self.df = nn.Linear(num_gauss, basis)\n",
    "        self.interaction = InteractionBlock(basis, basis)\n",
    "        self.mlp = nn.Sequential(nn.Linear(basis, hidden),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(hidden, 1))\n",
    "    \n",
    "    def forward(self, Z, D, sizes):\n",
    "        C = self.C_embed(Z)\n",
    "        d_hat = self.df(D)\n",
    "        \n",
    "        for _ in range(self.T):\n",
    "            C = C + self.interaction(C, d_hat, sizes)\n",
    "            \n",
    "        E = self.mlp(C).squeeze()\n",
    "        mask = utils.mask_1d(sizes, max_atoms)\n",
    "        mask = mask.to(E.device)\n",
    "        return (mask * E).sum(-1)#.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Embedding:\n",
    "        nn.init.normal_(m.weight)\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None: \n",
    "            m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MDTNN(basis, num_atoms, num_gauss, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(Zs, utils.transform_D(Ds, num_gauss), sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTNNModule(pl.LightningModule):\n",
    "    def __init__(self, basis, num_atoms, num_gauss, hidden, target):\n",
    "        super().__init__()\n",
    "        self.dtnn = MDTNN(basis, num_atoms, num_gauss, hidden)\n",
    "        self.target = target\n",
    "    \n",
    "    def forward(self, Z, D, sizes):\n",
    "        return self.dtnn(Z, D, sizes)\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        self.dataset = data.QM8Dataset('data/sdf.json', self.target, max_atoms, mu_min, delta_mu, mu_max, nrows=100, dist_method='graph')\n",
    "        size = len(self.dataset)\n",
    "        test_size = int(size * 0.2)\n",
    "        sizes = [size - 2*test_size, test_size, test_size]\n",
    "        self.train_dataset, self.test_dataset, self.valid_dataset = random_split(self.dataset, sizes)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, 15)\n",
    "    \n",
    "    def step(self, batch, batch_idx, loss_fn):\n",
    "        Z, D, sizes, target = batch\n",
    "        predict = self.forward(Z, D, sizes)\n",
    "        loss = loss_fn(predict, target)\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.step(batch, batch_idx, F.mse_loss)\n",
    "        result = pl.TrainResult(minimize=loss)\n",
    "        result.log('train_loss', loss, prog_bar=True)\n",
    "        result.log_dict({'train_loss': loss})\n",
    "        return result\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid_dataset, 50)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.step(batch, batch_idx, F.l1_loss)\n",
    "        \n",
    "        result = pl.EvalResult(checkpoint_on=loss)\n",
    "        result.log_dict({'val_loss': loss})\n",
    "        return result\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, 50)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        result = self.validation_step(batch, batch_idx)\n",
    "        result.rename_keys({'val_loss': 'test_loss'})\n",
    "        return result\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTNNModule(basis, num_atoms, num_gauss, hidden, 'E1-CC2')\n",
    "model.apply(init_weights)\n",
    "trainer = pl.Trainer(gpus=None, checkpoint_callback=ModelCheckpoint(), early_stop_callback=EarlyStopping(patience=10))\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 / .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dtnn.C_embed.weight.normal_(0, 1 / np.sqrt(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = nn.Embedding(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.weight.data.normal_(0, 1 / np.sqrt(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
